{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melvinwevers/audio_analysis/blob/main/1-working-with-audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Audio\n",
        "**Author**: Melvin Wevers, University of Amsterdam\n",
        "\n",
        "----\n",
        "\n",
        "First we will install some dependencies, then we will clone the GitHub repository so that we have easy access to the data folder."
      ],
      "metadata": {
        "id": "SgqJzVEsCsM4"
      },
      "id": "SgqJzVEsCsM4"
    },
    {
      "cell_type": "code",
      "source": [
        "# PyDub is a library for manipulating audio. For more see: http://pydub.com/\n",
        "!pip install pydub"
      ],
      "metadata": {
        "id": "7ipx7FrniK2R"
      },
      "id": "7ipx7FrniK2R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will clone the repo, so we can easily access the audio data through Colab.\n",
        "!git clone https://github.com/melvinwevers/audio_analysis.git\n",
        "\n",
        "# we will change our working directory\n",
        "%cd audio_analysis/"
      ],
      "metadata": {
        "id": "_jvetxQBiQGm"
      },
      "id": "_jvetxQBiQGm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show working directory contents\n",
        "%ls"
      ],
      "metadata": {
        "id": "AVy9a5nIDYJD"
      },
      "id": "AVy9a5nIDYJD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3eb4439a-c565-41dc-a4da-48581d8526d2",
      "metadata": {
        "id": "3eb4439a-c565-41dc-a4da-48581d8526d2"
      },
      "source": [
        "# Working with Audio\n",
        "\n",
        "In this notebook:\n",
        "1. We will look into file handling relating to audio files.\n",
        "2. We will process audio and extract different types of features from these audio files.\n",
        "3. Lastly, we will briefly show how such features can be used in a classification task.\n",
        "\n",
        "We will rely mostly on the `Librosa` library, but there are many more to explore. For example, `pyAudioAnalysis`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9afb52e3-b897-4262-9c80-e0fe453431b2",
      "metadata": {
        "id": "9afb52e3-b897-4262-9c80-e0fe453431b2"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d3fa7f5-e9cd-47b8-9176-e4eb1e357f35",
      "metadata": {
        "id": "8d3fa7f5-e9cd-47b8-9176-e4eb1e357f35"
      },
      "source": [
        "## The Audio\n",
        "\n",
        "As sample data, I have included audio clips extracted from two different archives held by the _Meertens_ Institute in Amsterdam.\n",
        "This institute studies Dutch language and culture.\n",
        "\n",
        "1. The first data set includes songs from the [_Nederlandse Liederenbank_](https://meertens.knaw.nl/meertens-collectie/nederlandse-liederenbank/). These are Dutch folk songs.\n",
        "2. The second data includes interviews from the [_Volksverhalenbank_](https://www.verhalenbank.nl/). These are oral interviews in which folk stories were told.\n",
        "\n",
        "Both sources contain Dutch with sometimes heavy dialects.\n",
        "\n",
        "The `data` folder contains two folders: `liederenbank` and `vvb`. In both folders, we find a `metadata.csv` and a `data` folder. In the latter, we find the raw audio files (`mp3`) and transcriptions. The former is an aggregate of the two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b8a0bb3-f06b-4d5e-9c70-1e108e5d5ac2",
      "metadata": {
        "id": "4b8a0bb3-f06b-4d5e-9c70-1e108e5d5ac2"
      },
      "outputs": [],
      "source": [
        "# Here we detail the contents of the liederenbank folder.\n",
        "!ls data/liederenbank/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "224c7eb9-3cba-4087-9a05-f9f0f822f8d6",
      "metadata": {
        "id": "224c7eb9-3cba-4087-9a05-f9f0f822f8d6"
      },
      "outputs": [],
      "source": [
        "# Here we use Pandas to inspect the metadata file belonging to the Liederenbank\n",
        "df = pd.read_csv('data/liederenbank/metadata.csv')\n",
        "print(df.head())\n",
        "print(f'Number of records: {df.shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "864c780a-f062-42d9-a214-d55037281dc1",
      "metadata": {
        "id": "864c780a-f062-42d9-a214-d55037281dc1"
      },
      "source": [
        "## File Handling and Conversion\n",
        "\n",
        "The raw data is in `mp3` format. We will now convert these `mp3` files into `wave` files.\n",
        "\n",
        "Even though we cannot restore the audio fidelity that was lost during the compression into the smaller mp3 format, wave files are a more common format and are easier to work with across libraries. Working with mp3s can sometimes leads to conversion errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9515770d-7985-40b0-85b1-91e40a6fb54c",
      "metadata": {
        "id": "9515770d-7985-40b0-85b1-91e40a6fb54c"
      },
      "outputs": [],
      "source": [
        "# here we define an input path, i.e. the original mp3\n",
        "# and an output path, or the name of the file that we want to save\n",
        "\n",
        "input_path = 'data/liederenbank/data/OGL14103b.mp3'\n",
        "output_path = 'data/OGL14103b.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8d5604-d759-49d5-9ffb-4e7e860cd825",
      "metadata": {
        "id": "4e8d5604-d759-49d5-9ffb-4e7e860cd825"
      },
      "outputs": [],
      "source": [
        "# We use the AudioSegment Library to load the mp3 and convert it into a wave file.\n",
        "# You can try and export to different audio formats.\n",
        "sound = AudioSegment.from_mp3(input_path)\n",
        "sound.export(output_path, format='wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the audio file.\n",
        "\n",
        "We will use Librosa to load the audio file. After loading the function returns two variables:\n",
        "1. `y`, which contains the audio signal, i.e. an array containing the numbers representing the audio\n",
        "2. `sr` which represents the signal rate. We specify the signal rate (or hz) at 44.1Khz. This is a default value for wave, or audio found on, for example, compact discs."
      ],
      "metadata": {
        "id": "TPaEmTy2Fd8Y"
      },
      "id": "TPaEmTy2Fd8Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f7dcd0-fb74-41e7-89f2-b6ac17330df5",
      "metadata": {
        "id": "84f7dcd0-fb74-41e7-89f2-b6ac17330df5"
      },
      "outputs": [],
      "source": [
        "y, sr = librosa.load(output_path, sr=44100)\n",
        "\n",
        "print(f'The audio signal is a: {type(y)}')\n",
        "print(f'The Signal Rate is: {sr}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we inspect a slice of the audio signal.\n",
        "y[1000:1100]"
      ],
      "metadata": {
        "id": "TslMv953F7HF"
      },
      "id": "TslMv953F7HF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we use the Audio function to create an interactive audio player\n",
        "Audio(data=y, rate=sr) # long clips might need to be clipped. You can use Python slicing."
      ],
      "metadata": {
        "id": "5orhxSrBFY02"
      },
      "id": "5orhxSrBFY02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54f6b64f-f5cc-4fc1-87bf-939444b2d6aa",
      "metadata": {
        "id": "54f6b64f-f5cc-4fc1-87bf-939444b2d6aa"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,3))\n",
        "librosa.display.waveshow(y, sr=sr, color='blue')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises\n",
        "1. Try and slice the audio file to a shorter segment\n",
        "2. Load a different file and plot it next to the previous one, either side-by-side, or in one plot. It might be handy to write a short function for loading audio files using the `input path` as a parameter.\n",
        "3. Describe the differences between the two sound files based on what you see in the visualizations of the wave forms\n",
        "4. Change the 'numbers' in the signal, through multiplication, normalizing, etc? Describe what happens to the sound after the adjustments."
      ],
      "metadata": {
        "id": "qItGfx_9jfwN"
      },
      "id": "qItGfx_9jfwN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features\n",
        "\n",
        "In the next part, we will turn to audio features, and how they can be extracted from the audio files. We will look into spectral features and tonal features."
      ],
      "metadata": {
        "id": "jZd0srpBohaH"
      },
      "id": "jZd0srpBohaH"
    },
    {
      "cell_type": "markdown",
      "id": "9bff74ed-cc21-4f9a-9589-d82da6138e99",
      "metadata": {
        "id": "9bff74ed-cc21-4f9a-9589-d82da6138e99"
      },
      "source": [
        "## Spectral Features\n",
        "\n",
        "Audio features that capture information on frequency and power distribution. This maps onto timbre and texture of sounds across different frequencies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "361f69fd-8ef7-4022-99d7-93851f8462ed",
      "metadata": {
        "id": "361f69fd-8ef7-4022-99d7-93851f8462ed"
      },
      "source": [
        "### Mel-Spectrogram\n",
        "\n",
        "The mel-scale is a perceptual scale of pitches. It is used for classification and retrieval tasks. Rather than using the raw signal it relates to the perception of sound,  i.e. how we hear sounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e494776-c00d-42ff-a866-0f08a90b8913",
      "metadata": {
        "id": "3e494776-c00d-42ff-a866-0f08a90b8913"
      },
      "outputs": [],
      "source": [
        "# compute mel-spectogram\n",
        "mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b059a0c-9a15-47a8-a9d9-ccdceb8c0bb5",
      "metadata": {
        "id": "9b059a0c-9a15-47a8-a9d9-ccdceb8c0bb5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10 ,4))\n",
        "# power_to_db converts spectrogram to logarithmic power (i.e. a way to express it in Decibels)\n",
        "librosa.display.specshow(librosa.power_to_db(mel_spectrogram, ref=np.max), sr=sr, hop_length=512, y_axis=\"mel\", x_axis=\"time\")\n",
        "plt.colorbar(format=\"%+2.0f db\")\n",
        "plt.title('Mel Spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises\n",
        "1. Describe what you see in the Mel Spectrogram\n",
        "2. Plot the same for a different audio file."
      ],
      "metadata": {
        "id": "YdmGdoSDpAMb"
      },
      "id": "YdmGdoSDpAMb"
    },
    {
      "cell_type": "markdown",
      "id": "6c46af60-aa4c-48ee-bddc-267aef262c21",
      "metadata": {
        "id": "6c46af60-aa4c-48ee-bddc-267aef262c21"
      },
      "source": [
        "## Mel-Frequency Cepstral Coefficients\n",
        "\n",
        "A cepstrum (reverse of Spectrum) is the outcome of a mathematical transformation. The aim is to better understand periodic structures in sound. More info [here](https://en.wikipedia.org/wiki/Cepstrum).\n",
        "\n",
        "Using Cepstrals (plural of cepstrum) allows you to separate the different sources producing variation in the sound, for example different instruments or multiple people speaking.\n",
        "\n",
        "The Mel Spectrogram provides a time-frequency representation of the audio signal, while MFCCs are a compact representation of spectral features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e386a77a-5964-429a-92b7-a49356e92bae",
      "metadata": {
        "id": "e386a77a-5964-429a-92b7-a49356e92bae"
      },
      "outputs": [],
      "source": [
        "# extracting Mel-Frequency Cepstral Coefficients\n",
        "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
        "# convert mel spectrogram to MFCC in logarithmic form\n",
        "mfccs_dbs = librosa.feature.mfcc(S=librosa.power_to_db(mel_spectrogram), sr=sr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13bb2e29-243c-4366-a7c6-a7fb2c04e65c",
      "metadata": {
        "id": "13bb2e29-243c-4366-a7c6-a7fb2c04e65c"
      },
      "source": [
        "## Spectral Contrast\n",
        "\n",
        "Technique to measure differences in magnitudes between adjacent frequency bands. A higher spectral contrast refers to a 'brighter' sound, while less contrast refers to 'duller' sounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05a4a0c3-80ee-440b-ad55-33f1dd788443",
      "metadata": {
        "id": "05a4a0c3-80ee-440b-ad55-33f1dd788443"
      },
      "outputs": [],
      "source": [
        "spectral_contrast = librosa.feature.spectral_contrast(y=y, n_fft=2048, hop_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4af85678-93e7-43f9-99f4-bdf3c43d06d5",
      "metadata": {
        "id": "4af85678-93e7-43f9-99f4-bdf3c43d06d5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "librosa.display.specshow(spectral_contrast, sr=sr, hop_length=512, x_axis=\"time\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise\n",
        "1. What does the spectral contrast represent for your clip?\n",
        "2. How does this relate to Mel-Spectrogram?\n",
        "3. Load a different clip and compare the output."
      ],
      "metadata": {
        "id": "hzpyexUuvyyd"
      },
      "id": "hzpyexUuvyyd"
    },
    {
      "cell_type": "markdown",
      "id": "10d263ec-319e-4a75-9c8e-d099cae6f357",
      "metadata": {
        "id": "10d263ec-319e-4a75-9c8e-d099cae6f357"
      },
      "source": [
        "## Chroma Features\n",
        "\n",
        "These features capture the harmonic and melodic structure. Each feature mapts onto a pitch class (C, C#, D, D# etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab85cbb1-53a0-4cbd-8a82-09cac0602dd9",
      "metadata": {
        "id": "ab85cbb1-53a0-4cbd-8a82-09cac0602dd9"
      },
      "outputs": [],
      "source": [
        "chroma_features = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "librosa.display.specshow(chroma_features, sr=sr, hop_length=512, x_axis=\"time\", y_axis=\"chroma\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification using features"
      ],
      "metadata": {
        "id": "cdZkJNK2x4O8"
      },
      "id": "cdZkJNK2x4O8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b4193d-c6f2-4657-bc5f-25e5d8bc38f4",
      "metadata": {
        "id": "f6b4193d-c6f2-4657-bc5f-25e5d8bc38f4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9fb8d27-8674-421a-983b-028e9d8cc30c",
      "metadata": {
        "id": "a9fb8d27-8674-421a-983b-028e9d8cc30c"
      },
      "outputs": [],
      "source": [
        "def convert_mp3_to_wav(mp3_folder, wav_folder):\n",
        "  \"\"\"\n",
        "  Converts all MP3 audio files in a specified folder to WAV format and saves them in another folder.\n",
        "\n",
        "  Parameters:\n",
        "    - mp3_folder (str): The path to the source folder containing MP3 files to be converted.\n",
        "    - wav_folder (str): The path to the target folder where the converted WAV files will be saved.\n",
        "  \"\"\"\n",
        "\n",
        "  # Check if the source folder exists\n",
        "  if not os.path.isdir(mp3_folder):\n",
        "      raise ValueError(f\"The source folder '{mp3_folder}' does not exist or is not a directory.\")\n",
        "\n",
        "  # Create the target folder if it doesn't exist\n",
        "  os.makedirs(wav_folder, exist_ok=True)\n",
        "\n",
        "  # Initialize a counter to track the number of files converted\n",
        "  converted_files_count = 0\n",
        "\n",
        "  for mp3_file in os.listdir(mp3_folder):\n",
        "      if mp3_file.lower().endswith(\".mp3\"):\n",
        "          mp3_path = os.path.join(mp3_folder, mp3_file)\n",
        "          wav_file_name = os.path.splitext(mp3_file)[0] + \".wav\"\n",
        "          wav_path = os.path.join(wav_folder, wav_file_name)\n",
        "\n",
        "          try:\n",
        "              # Load MP3 audio and convert to WAV\n",
        "              audio = AudioSegment.from_mp3(mp3_path)\n",
        "              audio.export(wav_path, format=\"wav\")\n",
        "              print(f\"Converted '{mp3_file}' to '{wav_file_name}'\")\n",
        "              converted_files_count += 1\n",
        "          except Exception as e:\n",
        "              print(f\"Failed to convert '{mp3_file}' due to an error: {e}\")\n",
        "\n",
        "  if converted_files_count == 0:\n",
        "      print(\"No MP3 files found to convert.\")\n",
        "  else:\n",
        "      print(f\"Successfully converted {converted_files_count} files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa404300-d00a-49d8-8e1e-4492a47f7d0e",
      "metadata": {
        "id": "aa404300-d00a-49d8-8e1e-4492a47f7d0e"
      },
      "outputs": [],
      "source": [
        "# convert liederenbank\n",
        "mp3_folder = \"data/liederenbank/data/\"\n",
        "wav_folder = \"data/liederenbank_wave\"\n",
        "\n",
        "# Convert MP3 files to WAV\n",
        "convert_mp3_to_wav(mp3_folder, wav_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396615a0-d83f-49ac-9e64-959c4c82531b",
      "metadata": {
        "id": "396615a0-d83f-49ac-9e64-959c4c82531b"
      },
      "outputs": [],
      "source": [
        "# convert ovv\n",
        "mp3_folder = \"data/vvb/data/\"\n",
        "wav_folder = \"data/vvb_wave\"\n",
        "\n",
        "# Convert MP3 files to WAV\n",
        "convert_mp3_to_wav(mp3_folder, wav_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_path, feature_type='mfcc', **kwargs):\n",
        "    \"\"\"\n",
        "    Extracts specified audio features from a given audio file.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): Path to the audio file.\n",
        "    - feature_type (str): Type of audio feature to extract. Supported types are 'mfcc', 'chroma', and 'spectral_contrast'.\n",
        "    - **kwargs: Additional keyword arguments to pass to the Librosa feature extraction function.\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray: Extracted audio features.\n",
        "    \"\"\"\n",
        "    # Validate the feature type\n",
        "    if feature_type not in ['mfcc', 'chroma', 'spectral_contrast']:\n",
        "        raise ValueError(\"Unsupported feature_type. Please choose from 'mfcc', 'chroma', 'spectral_contrast'\")\n",
        "\n",
        "    # Load the audio file\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path)\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading audio file: {e}\")\n",
        "\n",
        "    # Feature extraction using dictionary mapping\n",
        "    feature_functions = {\n",
        "        'mfcc': librosa.feature.mfcc,\n",
        "        'chroma': librosa.feature.chroma_stft,\n",
        "        'spectral_contrast': librosa.feature.spectral_contrast\n",
        "    }\n",
        "\n",
        "    # Extract features\n",
        "    try:\n",
        "        features = feature_functions[feature_type](y=y, sr=sr, **kwargs)\n",
        "        # Compute the mean of the features\n",
        "        features = np.mean(features, axis=1)\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error extracting {feature_type} features: {e}\")\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "def process_files(folder, label, feature_type, X, y):\n",
        "    \"\"\"\n",
        "    Processes audio files in a specified folder, extracting features and returning input for classification.\n",
        "\n",
        "    Parameters:\n",
        "    - folder (str): Path to the folder containing audio files.\n",
        "    - label (str or int): Label to assign to all files processed from this folder.\n",
        "    - feature_type (str): Type of audio feature to extract (e.g., 'mfcc', 'chroma', 'spectral_contrast').\n",
        "    - X (list): List to append extracted features to.\n",
        "    - y (list): List to append labels to.\n",
        "    \"\"\"\n",
        "    # Check if the specified folder exists\n",
        "    if not os.path.isdir(folder):\n",
        "        raise ValueError(f\"The specified folder '{folder}' does not exist or is not a directory.\")\n",
        "\n",
        "    processed_files_count = 0\n",
        "\n",
        "    for file_name in os.listdir(folder):\n",
        "        if file_name.lower().endswith('.wav'):\n",
        "            file_path = os.path.join(folder, file_name)\n",
        "\n",
        "            try:\n",
        "                features = extract_features(file_path, feature_type=feature_type)\n",
        "                X.append(features)\n",
        "                y.append(label)\n",
        "                processed_files_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process '{file_name}' due to an error: {e}\")\n",
        "\n",
        "    if processed_files_count == 0:\n",
        "        print(f\"No '.wav' files found in '{folder}'.\")\n",
        "    else:\n",
        "        print(f\"Successfully processed {processed_files_count} files from '{folder}'.\")\n"
      ],
      "metadata": {
        "id": "0BKAF8OKyt6A"
      },
      "id": "0BKAF8OKyt6A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data for classification"
      ],
      "metadata": {
        "id": "xqSrNrN0zhgQ"
      },
      "id": "xqSrNrN0zhgQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f87a3a-dac9-469b-b58f-11cd67ef439b",
      "metadata": {
        "id": "e4f87a3a-dac9-469b-b58f-11cd67ef439b"
      },
      "outputs": [],
      "source": [
        "# Paths to the folders containing WAV files for different classes\n",
        "class1_folder = \"data/liederenbank_wave/\"\n",
        "class2_folder = \"data/vvb_wave/\"\n",
        "\n",
        "# Extract features and create dataset\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "\n",
        "feature_type = 'mfcc'  # 'spectral_contrast', 'mfcc', 'chroma'\n",
        "\n",
        "# Process files from both classes\n",
        "process_files(class1_folder, 0, feature_type, X, y)\n",
        "process_files(class2_folder, 1, feature_type, X, y)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdf64b2c-385a-439d-8795-c1f438b98e96",
      "metadata": {
        "id": "fdf64b2c-385a-439d-8795-c1f438b98e96"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = svm_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises\n",
        "1. Vary the feature type\n",
        "2. Describe what the classification algorithm does\n",
        "3. Try replicating this on your own dataset of audio files (_optional_)"
      ],
      "metadata": {
        "id": "U47BiuaRz8BP"
      },
      "id": "U47BiuaRz8BP"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "whisper",
      "language": "python",
      "name": "whisper"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}